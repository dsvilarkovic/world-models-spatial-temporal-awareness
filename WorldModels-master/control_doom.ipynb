{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"control_doom.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"aDIMqtcoGyf_","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xoRNDeTAI3C-","colab_type":"code","colab":{}},"source":["drive.mount('/content/drive', force_remount=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lkz3PpC2LVKM","colab_type":"text"},"source":["Set this to your folder's location."]},{"cell_type":"code","metadata":{"id":"lsSC1v6eI4lI","colab_type":"code","colab":{}},"source":["os.chdir('/content/drive/My Drive/DL/WorldModels-master/')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lD5o5wGwLaAf","colab_type":"text"},"source":["Install requirements (only for generating rollouts, all other commands work without this)\n","*takes some time*"]},{"cell_type":"code","metadata":{"id":"4R1JRfOwFyTD","colab_type":"code","colab":{}},"source":["!sudo apt-get update"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aNevC6W_GnAD","colab_type":"code","colab":{}},"source":["%%bash\n","# Install deps from \n","# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n","\n","apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n","nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n","libopenal-dev timidity libwildmidi-dev unzip\n","\n","# Boost libraries\n","apt-get install libboost-all-dev\n","\n","# Lua binding dependencies\n","apt-get install liblua5.1-dev"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"21eFzqAzZwUk","colab_type":"code","colab":{}},"source":["!pip install scipy==1.1.0 cupy box2d-py gym vizdoom==1.1.7"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1MRoAthua56b","colab_type":"text"},"source":["#Train new Model\n","Running the following cells will create a new model RNN (2) as described in the report. To train a model as RNN (1), uncomment line 93 in 02_train_doom_vae.py and comment line 92.<br><br>\n","**IMPORTANT**<br>\n","Some of the following commands must be run twice, because of a timeout. Since we have about 10'000 rollouts per game and need to fetch the filelist, Drive times out. If run twice, Drive will take the partially loaded list from cache and complete it.<br><br>\n","**ALSO IMPORTANT**<br>\n","Set a unique model_name and an alpha in the following cell and replace YOUR_MODEL_NAME and SET_YOUR_ALPHA by these values (by the strings, e.g. my_fancy_model, not the variable model_name)."]},{"cell_type":"code","metadata":{"id":"2mc8M05PTXhE","colab_type":"code","colab":{}},"source":["# set a unique new model name\n","model_name = \"YOUR_MODEL_NAME\"\n","# set an alpha\n","alpha = .75"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DHmjL0YgKOKb","colab_type":"text"},"source":["##Generate VAE training Data\n","Arguments: \n","*  --num_rollouts (number of rollouts to generate)\n","*  --game (only \"DoomTakeCover\" works)\n","\n","The rollouts are saved in /data/rollout_doom"]},{"cell_type":"code","metadata":{"id":"jYwG8UQBI58g","colab_type":"code","colab":{}},"source":["!python3 01_generate_doom_data_bs.py --game DoomTakeCover --num_rollouts 10000"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a-kyUKO5RV_r","colab_type":"text"},"source":["**Analyze rollouts**<br>\n","The first time you run this cell, you will get a timeout. Just run it again and the filelist will stay in cache."]},{"cell_type":"code","metadata":{"id":"ZIk86ttLRaRL","colab_type":"code","colab":{}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","filelist = os.listdir(\"./data/rollout_doom\")\n","filelist = [x for x in filelist if x != '.DS_Store']\n","print(\"# of rollouts\", len(filelist))\n","\n","data = np.load(\"./data/rollout_doom/\"+filelist[0])\n","print(\"Frames shape:\", data['frames'].shape)\n","print(\"The first rollout contains\", data['frames'].shape[0], \"images with dimensions\", data['frames'].shape[1:])\n","print(\"Actions shape:\", data['actions'].shape)\n","print(\"Rewards shape:\", data['rewards'].shape)\n","\n","plt.imshow(data['frames'][0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Sj_atJ4G3RT","colab_type":"text"},"source":["##Train the VAE\n","The weights of the model are regularly saved, so the training can be interrupted at any time without loosing any progress.<br>\n","Arguments: \n","\n","*   --new_model (creates new folder in /vae/)\n","*   --model_name (to distinguish models)\n","*   --S (how many rollouts to skip)\n","*   --N (index of last rollout to use)\n","*   --alpha (amount of zooming and variance, set alpha = 1 for simple, non-augmenting vae, alpha < 1 makes an augmenting VAE. The smaller alpha, the bigger the zooming effect)\n","\n","This call will create a folder /vae/YOUR_MODEL_NAME containing the saved weights and a tensorboard log.\n","\n"]},{"cell_type":"code","metadata":{"id":"iV6cGc5LYlM5","colab_type":"code","colab":{}},"source":["!python 02_train_doom_vae.py --new_model --model_name YOUR_MODEL_NAME --alpha SET_YOUR_ALPHA"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lt1hm9OQSllp","colab_type":"text"},"source":["**Analyze VAE**"]},{"cell_type":"code","metadata":{"id":"vWyg07RUULrb","colab_type":"code","cellView":"form","colab":{}},"source":["#@title ####_Cropping & scaling functions (run this before the next cell)_\n","import cv2\n","def crop(image, scale):\n","  size = len(image)\n","  newsize = int(np.round(size * scale))\n","  border = int(round((size-newsize) / 2))\n","  left = border\n","  right = left + newsize\n","  top = border\n","  bottom = top + newsize\n","  return image[top:bottom, left:right]\n","\n","def scale(image):\n","  return cv2.resize(image, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PtBo4irxS2gk","colab_type":"code","colab":{}},"source":["from vae.arch import VAE\n","vae = VAE()\n","vae.set_weights(\"./vae/\"+model_name+\"/\"+model_name+\"_weights.h5\")\n","plt.imshow(vae.full_model.predict(scale(data['frames'][0]/255.)[np.newaxis, :,:,:])[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UgfVvhjmJcl-","colab_type":"text"},"source":["##Generate RNN training data\n","Set the exact same settings as before.<br>\n","This call will create a folder /data/series_YOUR_MODEL_NAME containing the rollouts convertet into the latent representation."]},{"cell_type":"code","metadata":{"id":"G97TqviB95ZH","colab_type":"code","colab":{}},"source":["!python 03_generate_doom_rnn_data.py --model_name YOUR_MODEL_NAME --alpha SET_YOUR_ALPHA"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q8_9jEg0JulX","colab_type":"text"},"source":["##Train the RNN\n","The weights of the model are regularly saved, so the training can be interrupted at any time without loosing any progress.<br>\n","Same arguments as before, except no --alpha.<br>\n","This call will create a folder /rnn/YOUR_MODEL_NAME containing the saved weights and a tensorboard log."]},{"cell_type":"code","metadata":{"id":"wBKGZOGpW8V2","colab_type":"code","colab":{}},"source":["!python 04_train_doom_rnn.py --new_model --model_name YOUR_MODEL_NAME"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E37hcZtgVxdH","colab_type":"text"},"source":["**Analyse RNN**"]},{"cell_type":"code","metadata":{"id":"NnfUjagqrEmp","colab_type":"code","colab":{}},"source":["import cv2\n","data = np.load(\"data/rollout_doom/\"+filelist[5000])['frames']/255.\n","actions = np.zeros((len(data)-1, 3))\n","actions[:, :2] = np.load(\"data/rollout_doom/\"+filelist[5000])['actions']\n","rewards = np.load(\"data/rollout_doom/\"+filelist[5000])['rewards']\n","\n","imgs = []\n","for i in data:\n","  imgs.append(cv2.resize(crop(i, alpha), dsize=(64, 64), interpolation=cv2.INTER_CUBIC))\n","imgs = np.asarray(imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v5WdJDtPtChm","colab_type":"code","colab":{}},"source":["from rnn.arch import RNN\n","rnn = RNN()\n","rnn.set_weights('./rnn/'+model_name+'/'+model_name+'weights.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8kOz6Ggjr08","colab_type":"code","cellView":"form","colab":{}},"source":["#@title ####_Functions to reconstruct images and compare results (run this before the next cell)_\n","GAUSSIAN_MIXTURES = 5\n","Z_DIM = 32\n","d = GAUSSIAN_MIXTURES * Z_DIM\n","\n","def sample_z(mu, log_sigma):\n","    z =  mu + (np.exp(log_sigma)) * np.random.randn(*log_sigma.shape) * 0.5\n","    return z\n","\n","def get_mixture_coef(z_pred):\n","\n","    log_pi, mu, log_sigma = np.split(z_pred, 3, 1)\n","    log_pi = log_pi - np.log(np.sum(np.exp(log_pi), axis = 1, keepdims = True))\n","\n","    return log_pi, mu, log_sigma\n","\n","def get_pi_idx(x, pdf):\n","  # samples from a categorial distribution\n","    N = pdf.size\n","    accumulate = 0\n","    for i in range(0, N):\n","        accumulate += pdf[i]\n","        if (accumulate >= x):\n","            return i\n","    random_value = np.random.randint(N)\n","    #print('error with sampling ensemble, returning random', random_value)\n","    return random_value\n","\n","def sample_next_mdn_output(obs, h, c):\n","    d = GAUSSIAN_MIXTURES * Z_DIM\n","    \n","    out = rnn.forward.predict([obs,np.array([h]),np.array([c])])\n","    \n","    y_pred = out[0][0][0]\n","    new_h = out[1][0]\n","    new_c = out[2][0]\n","    \n","    z_pred = y_pred[:3*d]\n","    rew_pred = y_pred[-1]\n","\n","    z_pred = np.reshape(z_pred, [-1, GAUSSIAN_MIXTURES * 3])\n","\n","    log_pi, mu, log_sigma = get_mixture_coef(z_pred)\n","    \n","    chosen_log_pi = np.zeros(Z_DIM)\n","    chosen_mu = np.zeros(Z_DIM)\n","    chosen_log_sigma = np.zeros(Z_DIM)\n","    \n","    pi = np.copy(log_pi)\n","    pi = np.exp(pi)\n","    pi /= pi.sum(axis=1).reshape(Z_DIM, 1)\n","    \n","    for j in range(Z_DIM):\n","        \n","        idx = get_pi_idx(np.random.rand(), pi[j])\n","        chosen_log_pi[j] = idx\n","        chosen_mu[j] = mu[j,idx]\n","        chosen_log_sigma[j] = log_sigma[j,idx]\n","        \n","    next_z = sample_z(chosen_mu, chosen_log_sigma)\n","\n","    if rew_pred > 0:\n","        next_reward = 1\n","    else:\n","        next_reward = 0\n","\n","    return next_z, chosen_mu, chosen_log_sigma, chosen_log_pi, rew_pred, next_reward, new_h, new_c"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQABMaSy_bge","colab_type":"code","colab":{}},"source":["from IPython import display\n","\n","next_h = np.zeros(256)\n","next_c = np.zeros(256)\n","next_z = np.hstack([vae.encoder.predict(imgs)[1:], actions, rewards.reshape(-1, 1)])[0].reshape(1, -1, 36)\n","for i in range(len(imgs)-1):\n","    next_z = np.hstack([vae.encoder.predict(imgs)[1:], actions, rewards.reshape(-1, 1)])[i].reshape(1, -1, 36)\n","    next_z, chosen_mu, chosen_log_sigma, chosen_pi, rew_pred, next_reward, next_h, next_c \\\n","    = sample_next_mdn_output(next_z, next_h, next_c)\n","        \n","    next_z_decoded = vae.decoder.predict(np.array([next_z]))[0]\n","    next_z = np.concatenate([next_z, [-1,1,0], [next_reward]])\n","\n","    fig = plt.figure(figsize=(15, 8))\n","    sub = fig.add_subplot(1, 4, 1)\n","    sub.set_title(str(i)+\" Original (target) image\")\n","    sub.imshow(data[i+1])\n","    sub = fig.add_subplot(1, 4, 2)\n","    sub.set_title(str(i)+\" Input image\")\n","    sub.imshow(imgs[i+1])\n","    sub = fig.add_subplot(1, 4, 3)\n","    sub.set_title(str(i)+\" Output image from VAE\")\n","    sub.imshow(vae.full_model.predict(imgs[i+1].reshape(1, 64, 64, 3))[0])\n","    sub = fig.add_subplot(1, 4, 4)\n","    sub.set_title(str(i)+\" Output image from RNN\")\n","    sub.imshow(next_z_decoded)\n","    plt.show()"],"execution_count":0,"outputs":[]}]}